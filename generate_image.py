# TensorFlow ã¨ tf.keras ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import tensorflow as tf
from tensorflow import keras

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numpy as np
import matplotlib.pyplot as plt

import os
import pathlib
import time
import datetime
import glob
import random
import cv2

from PIL import Image
from IPython import display

def saved_images(model, test_input, number):
    prediction = model(test_input, training=False)
    if CHANNEL == 1:
        predict_image = prediction[0].numpy().flatten().reshape(256, 256) # ãƒ¢ãƒã‚¯ãƒ­ç”»åƒã®å ´åˆ
        plt.imsave('predict_images/predict_{}.jpg'.format(number), predict_image, cmap="gray")
    else:
        predict_image = prediction[0].numpy().flatten().reshape(256, 256, 3)
        plt.imsave('predict_images/predict_{}.jpg'.format(number), predict_image)


# å­¦ç¿’ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
def read_single_image(dataset, batch_size=1, size=256):
        train_image_dataset = dataset

        batch_input = [] # å…¥åŠ›ç”»åƒã®ãƒãƒƒãƒ

        for pd in train_image_dataset:
            input = pd[0] # å®Ÿæ…‹ã¯å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹
            
            # ãƒ¢ãƒã‚¯ãƒ­ç”»åƒã®å ´åˆã€ãƒ¢ãƒã‚¯ãƒ­ç”»åƒã¨ã—ã¦ç”»åƒã‚’å–å¾—
            if CHANNEL == 1:
                input = Image.open(input).convert("L")
                input = input.resize((256, 256))
            else:
                input = Image.open(input)
                input = input.resize((256, 256))
            # å…¥åŠ›ç”»åƒã®å½¢å¼ï¼ˆã‚·ã‚§ã‚¤ãƒ—ï¼‰ã‚’tensorflowã€kerasã§å­¦ç¿’,æ¨è«–ã™ã‚‹ãŸã‚ã«å¤‰æ›
            input = np.reshape(input, [1, size, size, CHANNEL])
            # å…¥åŠ›ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            input = tf.cast(tf.convert_to_tensor(np.asarray(input)), dtype=tf.float32) / 255.

            # å…¥åŠ›ç”»åƒã®ãƒãƒƒãƒ
            batch_input += [input]
            
            # ä»Šå›ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯1ãªã®ã§ã€å˜ç´”ã«ãƒšã‚¢ã®ç”»åƒã‚’è¿”ã—ã¦ã„ã‚‹ã ã‘
            if len(batch_input) ==  batch_size:
                batch_input = tf.concat(batch_input, axis=0)

                yield {'input': batch_input}
                batch_input = []

def test_data_loader(batch_size=1):
    input_paths = sorted(glob.glob(os.path.join(str(PATH), '*.png'))) # QRã‚³ãƒ¼ãƒ‰ç”»
    # input_paths = sorted(glob.glob(os.path.join(str(PATH) + "/test/" , 'tr*.jpg'))) # æ•°å­—ç”»åƒ
    records = []
    for input in input_paths:
        records += [[input]]

    return read_single_image(records, batch_size=batch_size)

# ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©ã«ä½¿ç”¨
def upsample(filters, size,  dropout=0.5, max_pool=True, batch_norm=True):
    initializer = tf.random_normal_initializer(0., 0.02)

    result = tf.keras.Sequential()
    result.add(
        # ç•³ã¿è¾¼ã¿å±¤ã®è¿½åŠ ï¼ˆã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒ«ã«ä½¿ç”¨ï¼‰
        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,
                                        padding='same',
                                        kernel_initializer=initializer,
                                        use_bias=False)
    )
    
    # max poolingã‚’è¡Œã†å ´åˆ
    if max_pool:
        result.add(tf.keras.layers.MaxPool2D(pool_size=(1, 1), strides=None, padding='same'))

    # ãƒãƒƒãƒãƒãƒ«ãƒ ã‚’è¡Œã†å ´åˆ
    if batch_norm:
        result.add(tf.keras.layers.BatchNormalization())

    # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã†å ´åˆ
    if dropout != None:
        result.add(tf.keras.layers.Dropout(dropout))
    result.add(tf.keras.layers.ReLU())

    return result

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©ã«ä½¿ç”¨
def downsample(filters, kernel_size, strides=2, dropout=0.5, max_pool=True, batch_norm=True):
    initializer = tf.random_normal_initializer(0., 0.02)

    result = tf.keras.Sequential()
    result.add(
        # ç•³ã¿è¾¼ã¿å±¤ã®è¿½åŠ 
        tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same',
                                kernel_initializer=initializer, use_bias=False))
    # max poolingã‚’è¡Œã†å ´åˆ
    if max_pool:
        result.add(tf.keras.layers.MaxPool2D(pool_size=(1, 1), strides=None, padding='same'))

    # ãƒãƒƒãƒãƒãƒ«ãƒ ã‚’è¡Œã†å ´åˆ
    if batch_norm:
        result.add(tf.keras.layers.BatchNormalization())
    
    # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã†å ´åˆ
    if dropout != None:
        result.add(tf.keras.layers.Dropout(dropout))

    result.add(tf.keras.layers.LeakyReLU())
    return result

# ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å®šç¾©
def Generator(image_shape):
    initializer = tf.random_normal_initializer(0., 0.02)
    # å…¥åŠ›ç”»åƒ
    input_image = keras.layers.Input(shape=image_shape, name='input_image')
    x = input_image

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©
    enc1 = downsample(n_E1, kernel_size_E1, stride_E1, DropOut_E1, MaxPooling_E1, BatchNorm_E1)(x) # æ­£ä½“ã¯å˜ç´”ãªç•³ã¿è¾¼ã¿å±¤
    enc2 = downsample(n_E2, kernel_size_E2 ,stride_E2, DropOut_E2, MaxPooling_E2, BatchNorm_E2)(enc1)
    enc3 = downsample(n_E3, kernel_size_E3, stride_E3, DropOut_E3, MaxPooling_E3, BatchNorm_E3)(enc2)
    enc4 = downsample(n_E4, kernel_size_E4, stride_E4, DropOut_E4, MaxPooling_E4, BatchNorm_E4)(enc3)
    enc5 = downsample(n_E5, kernel_size_E5 ,stride_E5, DropOut_E5, MaxPooling_E5, BatchNorm_E5)(enc4)
    enc6 = downsample(n_E6, kernel_size_E6 ,stride_E6, DropOut_E6, MaxPooling_E6, BatchNorm_E6)(enc5)
    enc7 = downsample(n_E7, kernel_size_E7 ,stride_E7, DropOut_E7, MaxPooling_E7, BatchNorm_E7)(enc6)
    enc8 = downsample(n_E8, kernel_size_E8, stride_E8, DropOut_E8, MaxPooling_E8, BatchNorm_E8)(enc7)

    # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©
    dec1 = upsample(n_E7, kernel_size_E7, DropOut_E7, MaxPooling_E7, BatchNorm_E7) # æ­£ä½“ã¯å˜ç´”ãªç•³ã¿è¾¼ã¿å±¤
    dec2 = upsample(n_E6, kernel_size_E6, DropOut_E6, MaxPooling_E6, BatchNorm_E6)
    dec3 = upsample(n_E5, kernel_size_E5, DropOut_E5, MaxPooling_E5, BatchNorm_E5)
    dec4 = upsample(n_E4, kernel_size_E4, DropOut_E4, MaxPooling_E4, BatchNorm_E4)
    dec5 = upsample(n_E3, kernel_size_E3, DropOut_E3, MaxPooling_E3, BatchNorm_E3)
    dec6 = upsample(n_E2, kernel_size_E2, DropOut_E2, MaxPooling_E2, BatchNorm_E2)
    dec7 = upsample(n_E1, kernel_size_E1, DropOut_E1, MaxPooling_E1, BatchNorm_E1)
    

    # ç”»åƒã‚’æ‹¡å¤§ã™ã‚‹å ´åˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
    # zoom = upsample(CHANNEL, 4)

    # ãƒã‚¤ãƒ‘ã‚¹ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ç‰¹å¾´é‡
    enc_value_list = [enc7, enc6, enc5, enc4, enc3, enc2, enc1]

    # ãƒã‚¤ãƒ‘ã‚¹ã™ã‚‹ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®ç‰¹å¾´é‡
    dec_value_list = [dec1, dec2, dec3, dec4, dec5, dec6, dec7]

    # ãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã†ã‹åˆ¤å®šã™ã‚‹ãƒ•ãƒ©ã‚°
    bipass_list = [Bipass_7, Bipass_6, Bipass_5, Bipass_4, Bipass_3, Bipass_2, Bipass_1]

    # ãƒã‚¤ãƒ‘ã‚¹å‡¦ç†ã®ãŸã‚ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®æœ€çµ‚å‡ºåŠ›ã‚’xã¨ã™ã‚‹
    x = enc8    

    # ãƒã‚¤ãƒ‘ã‚¹å‡¦ç†ã‚’è¡Œã£ã¦ã„ã‚‹éƒ¨åˆ†
    for dec, enc, bipass in zip(dec_value_list, enc_value_list, bipass_list):
        x = dec(x)
        # ãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã†ã‹ã‚’åˆ¤å®šã™ã‚‹
        if bipass:
            x = tf.keras.layers.Concatenate()([x, enc]) # ãƒã‚¤ãƒ‘ã‚¹ã—ã¦ã„ã‚‹è¡Œ

    # ç”»åƒã‚’æ‹¡å¤§ã™ã‚‹å ´åˆã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã™
    # if expantion:
    #     x = zoom(x)

    # å‡ºåŠ›ã®ãƒãƒ£ãƒãƒ«æ•°ã€ã‚«ãƒ©ãƒ¼ã ã¨3ã€ãƒ¢ãƒã‚¯ãƒ­ã ã¨1
    OUTPUT_CHANNELS = CHANNEL

    # å±¤ã®ä¹±æ•°ã‚’åˆæœŸåŒ–ã™ã‚‹ã‚‚ã®
    initializer = tf.random_normal_initializer(0., 0.02)

    # æœ€çµ‚å‡ºåŠ›å±¤
    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,
                                            strides=2,
                                            padding='same',
                                            kernel_initializer=initializer,
                                            activation='tanh')
    x = last(x)

    return tf.keras.Model(inputs=input_image, outputs=x)

CHANNEL = 1
# å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º
G_input_dim = (256, 256, CHANNEL) 
EPOCH = 20

# ç¬¬ï¼‘å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
n_E1 = 32 # ãƒãƒ£ãƒãƒ«æ•°
m_E1 = 128 # ç”»ç´ æ•°
stride_E1 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E1 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E1 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E1 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
BatchNorm_E1 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E1 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_1 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ 

# ç¬¬ï¼’å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E2 = 64 # ãƒãƒ£ãƒãƒ«æ•°
m_E2 = 64 # ç”»ç´ æ•°
stride_E2 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E2 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E2 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E2 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E2 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E2 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_2 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ 

# ç¬¬3å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E3 = 128 # ãƒãƒ£ãƒãƒ«æ•°
m_E3 = 128 # ç”»ç´ æ•°
stride_E3 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E3 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E3 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E3 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E3 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E3 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_3 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ 

# ç¬¬4å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E4 = 256 # ãƒãƒ£ãƒãƒ«æ•°
m_E4 = 256 # ç”»ç´ æ•°
stride_E4 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E4 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E4 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E4 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E4 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E4 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_4 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ 

# ç¬¬5å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E5 = 512 # ãƒãƒ£ãƒãƒ«æ•°
m_E5 = 512 # ç”»ç´ æ•°
stride_E5 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E5 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E5 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E5 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E5 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E5 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_5 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰

# ç¬¬6å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E6 = 512 # ãƒãƒ£ãƒãƒ«æ•°
m_E6 = 512 # ç”»ç´ æ•°
stride_E6 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E6 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E6 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E6 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E6 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E6 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_6 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰

# ç¬¬7å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E7 = 512 # ãƒãƒ£ãƒãƒ«æ•°
m_E7 = 512 # ç”»ç´ æ•°
stride_E7 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E7 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E7 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E7 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E7 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E7 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
Bipass_7 = True # ãƒã‚¤ãƒ‘ã‚¹ã®è¨­å®šï¼ˆãƒã‚¤ãƒ‘ã‚¹ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰


# ç¬¬8å±¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
n_E8 = 512 # ãƒãƒ£ãƒãƒ«æ•°
m_E8 = 512 # ç”»ç´ æ•°
stride_E8 = 2 # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º
kernel_size_E8 = 4 # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
MaxPooling_E8 = True # MaxPoolingã®è¨­å®šï¼ˆMaxPoolingã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰ğŸ‡²
ActivationFunc_E8 = "Leaky_ReLu" # æ´»æ€§åŒ–é–¢æ•°
alfa = 0.2
BatchNorm_E8 = True # ã€€ãƒãƒƒãƒæ­£è¦åŒ–ã®è¨­å®šï¼ˆæ­£è¦åŒ–ã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰
DropOut_E8 = 0.5 # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’è¡Œã‚ãªã„å ´åˆã¯Noneã«ã™ã‚‹ï¼‰

# ç”»åƒæ‹¡å¤§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
expantion = True # ç”»åƒã‚’conv2dã§ï¼’å€ã«æ‹¡å¤§ã™ã‚‹

PATH = "bottle/test/broken_large"
generator = Generator(G_input_dim)
generator.load_weights('checkpoints/cp-20.h5')
test_generator = test_data_loader(batch_size=1)
for i, test_loader_dict in enumerate(test_generator):
    example_input = test_loader_dict['input'] # å…¥åŠ›ç”»åƒã‚’å–å¾—ã™ã‚‹
    saved_images(generator, example_input, i)